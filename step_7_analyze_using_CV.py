#Create maps (raw+smoothed) in VCG Features project

#It needs feature window matrices generated by Step_6 and a table with the outcomes from the Step_1.
#This script iterartes through each feature window matrix.
#Inside each iteration, using 5-fold CV it:
#  - draws a map (raw+smoothed)
#  - identifies the optimal window in it
#  - renders an average maps from these iterations to show feature stability
#  - export the map into /figs_maps
#  - train a simple decision-tree classifier and evaluates it performance

#Finaly, this script generates a CV5_autofeatures*.pkl file
#with these automated CV results

#Warning - takes a very long time to proceed (>1 hour)
#Author - Filip Plesinger, ISI of the CAS, CZ
#2022-23

import numpy as np
from sklearn.model_selection import KFold
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from scipy.stats import mannwhitneyu
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.metrics import f1_score, accuracy_score
from scipy.ndimage import filters as sflt

#build from previous step 14:
#M:\d03\filip\pokusy\ai_fs\software\step_14_cross.py

def pline(chr="–", num=80):
    print(chr * num)


print("Automated optimalization during cross-validation")


fileAreas = "results_data/COG_expPAreas_offset_-05_06_220_lng_001_05_98.npy"
fileSums = "results_data/COG_expPADsums_offset_-05_06_220_lng_001_05_98.npy"
fileXSum = "results_data/COG_xSums_offset_-05_06_220_lng_001_05_98.npy"
filedXMean = "results_data/COG_dXmeans_offset_-05_06_220_lng_001_05_98.npy"
fileYSum = "results_data/COG_ySums_offset_-05_06_220_lng_001_05_98.npy"
filedYMean = "results_data/COG_dYmeans_offset_-05_06_220_lng_001_05_98.npy"
fileZSum = "results_data/COG_zSums_offset_-05_06_220_lng_001_05_98.npy"
filedZMean = "results_data/COG_dZmeans_offset_-05_06_220_lng_001_05_98.npy"

fileXamps = "results_data/COG_xAmps_offset_-05_06_220_lng_001_05_98.npy"
fileYamps = "results_data/COG_yAmps_offset_-05_06_220_lng_001_05_98.npy"
fileZamps = "results_data/COG_zAmps_offset_-05_06_220_lng_001_05_98.npy"

fileexpPADXs = "results_data/COG_expPADXs_offset_-05_06_220_lng_001_05_98.npy"
fileexpPADYs = "results_data/COG_expPADYs_offset_-05_06_220_lng_001_05_98.npy"
fileexpPADZs = "results_data/COG_expPADZs_offset_-05_06_220_lng_001_05_98.npy"

fileYsb0Name = "results_data/COG_ysb0_offset_-05_06_220_lng_001_05_98.npy"

print("Loading")
areas = np.load(fileAreas)
sums = np.load(fileSums)
xSums = np.load(fileXSum)
dXmean = np.load(filedXMean)
ySums = np.load(fileYSum)
dYmean = np.load(filedYMean)
zSums = np.load(fileZSum)
dZmean = np.load(filedZMean)

xAmps = np.load(fileXamps)
yAmps = np.load(fileYamps)
zAmps = np.load(fileZamps)

expPADXs = np.load(fileexpPADXs)
expPADYs = np.load(fileexpPADYs)
expPADZs = np.load(fileexpPADZs)

ysb0s=np.load(fileYsb0Name)

print("Done")

print("Dims areas:", areas.shape)
print("Dims sums:", sums.shape)
print("Dims x sum:", xSums.shape)
print("Dims dX mean:", dXmean.shape)
print("Dims y sum:", ySums.shape)
print("Dims dY mean:", dYmean.shape)
print("Dims z sum:", zSums.shape)
print("Dims ZX mean:", dZmean.shape)

print("Dims X amps:", xAmps.shape)
print("Dims Y amps:", yAmps.shape)
print("Dims Z amps:", zAmps.shape)

print("Dims expPADx:", expPADXs.shape)
print("Dims expPADy:", expPADYs.shape)
print("Dims expPADz:", expPADZs.shape)

print("Dims ysb0s:", ysb0s.shape)

pline()

print("Loading outcome")
dnm = "results_data/COG_Detected_170_cases-all_XYZQRS.pkl"
data = pd.read_pickle(dnm)
data=data[data.Measured=="Before"]
print("Done. Columns N=", data.shape[1])
print(data.columns)

if 1 == 1:
    pline("=")
    print("Sub-groups")

#    print("Unique rhythms:")
#    print(np.unique(data.Rhythm.values))

    #not used now
    sel = []
    for r in range(data.shape[0]):
        val = True
        sel.append(val)

    data = data[sel]

    areas = areas[sel]
    sums = sums[sel]
    xSums = xSums[sel]
    dXmean = dXmean[sel]
    ySums = ySums[sel]
    dYmean = dYmean[sel]
    zSums = zSums[sel]
    dZmean = dZmean[sel]

    xAmps = xAmps[sel]
    yAmps = yAmps[sel]
    zAmps = zAmps[sel]

    expPADXs = expPADXs[sel]
    expPADYs = expPADYs[sel]
    expPADZs = expPADZs[sel]

    ysb0s = ysb0s[sel]

    print("Selected cases:", data.shape[0])

gt = "Data"
gt = gt + "_" + str(data.shape[0]) + "_cases"
gt = gt.replace("/", "")

rows = np.zeros(data.shape[0])

nsplt = 5
kf = KFold(n_splits=nsplt, random_state=0, shuffle=True)

cr=0

pline("=")
print("Defining steps...")

#outcome = data.Outcome.values

offSteps = areas.shape[1]
lngSteps = areas.shape[2]

imH = offSteps / 15
imW = lngSteps / 10

strs = fileAreas.split("_")
offMin = float(strs[4]) / 10
offMax = float(strs[5]) / 10
lngMin = float(strs[8]) / 100  # tady bylo 10
lngMax = float(strs[9]) / 10

offStepsIm = float(strs[6])
offInc = (offMax - offMin) / offStepsIm
offLbs = ["%.2f" % f for f in np.arange(offMin, offMax, offInc)]

lngStepsIm = float(strs[10].replace(".npy", ""))
lngInc = (lngMax - lngMin) / lngStepsIm
lngLbs = ["%.2f" % f for f in np.arange(lngMin, lngMax, lngInc)]

oc = [(0.20 - lngMin) / lngInc, (0.275 - offMin) / offInc]
nc = [(0.35 - lngMin) / lngInc, (0.400 - offMin) / offInc]

# diagonala
al0 = [(0.01 - lngMin) / lngInc, (0.01 - offMin) / offInc]
al1 = [(0.5 - lngMin) / lngInc, (0.5 - offMin) / offInc]

# horizontala
zl0 = [(0.01 - lngMin) / lngInc, (0.0 - offMin) / offInc]
zl1 = [(0.5 - lngMin) / lngInc, (0.0 - offMin) / offInc]

pline("=")

features =["ysb0"]
features = ["expPArea", "expPADarea"]
features += ["expPADx", "expPADy","expPADz"]

features += ["xSum", "dXMean"]
features += ["ySum", "dYMean"]
features += ["zSum", "dZMean"]
features += ["xAmps", "yAmps", "zAmps"]

#features += ["Feas_Area","Feas_AreaX","Feas_AreaY","Feas_AreaZ"]
#features = ["dzMean","xSum"]

offsets=[]
durations=[]
aucsTrain = []
f1Trains=[]
f1Tests=[]

uniformSize=10
smoothType="median" #nebo "uniform"

gt = gt+"_SMOOTH_"+smoothType+str(uniformSize)

for ftr in features:
    pline("█")
    print("Feature",ftr)

    cr=0
    locOffs=[]
    locDurs=[]
    locAUCs=[]
    locF1Tr=[]
    locF1Te=[]

    mapAUCs = np.zeros((nsplt,offSteps, lngSteps))
    mapCVAV = np.zeros((offSteps,lngSteps))
    mapStdAUC = np.zeros((offSteps, lngSteps))

    for trainIndex,testIndex in kf.split(rows):

        pline("▒")
        print("Cross-validation run:",cr)
        #print("Train",trainIndex)
        #print("Test", testIndex)
        cr+=1
        pline()

        dataTrain = data.iloc[trainIndex,:]
        dataTest = data.iloc[testIndex,:]

        outcomeTrain = dataTrain["Recidive"].values
        outcomeTest = dataTest["Recidive"].values

        Rtrain = outcomeTrain == True
        Ntrain = outcomeTrain == False

        Rtest = outcomeTest == True
        Ntest = outcomeTest == False

        newFeatures = pd.DataFrame()

        mapAreasP = np.zeros((offSteps,lngSteps))
        mapAreasP[:] = np.nan

        mapAreasAUC = np.zeros((offSteps,lngSteps))
        mapAreasAUC[:] = np.nan

        mapMeansDiff = np.zeros((offSteps,lngSteps))
        mapMeansDiff[:] = np.nan



        vls = areas

        if ftr=="expPADarea":
            vls=sums

        if ftr=="xSum":
            vls = xSums

        if ftr == "dXMean":
            vls = dXmean

        if ftr=="ySum":
            vls = ySums

        if ftr == "dYMean":
            vls = dYmean

        if ftr=="zSum":
            vls = zSums

        if ftr == "dZMean":
            vls = dZmean

        if ftr=="xAmps":
            vls = xAmps
        if ftr=="yAmps":
            vls = yAmps
        if ftr=="zAmps":
            vls=zAmps

        if ftr=="expPADx":
            vls=expPADXs
        if ftr=="expPADy":
            vls=expPADYs
        if ftr=="expPADz":
            vls=expPADZs

        if ftr=="ysb0":
            vls=ysb0s


        #rozdělení na cross-validační bloky:
        vlsTrain = vls[trainIndex,:]
        vlsTest = vls[testIndex,:]

        if not "Feas_" in ftr:

            print("Seeking max AUC in ",ftr)

            for off in range(offSteps):
                for lng in range(lngSteps):

                    valsRSP = vlsTrain[Rtrain,off,lng]
                    valsNRSP = vlsTrain[Ntrain, off, lng]

                    valsRSP = valsRSP[~np.isnan(valsRSP)]
                    valsNRSP = valsNRSP[~np.isnan(valsNRSP)]

                    rspMean = np.mean(valsRSP)
                    nrspMean = np.mean(valsNRSP)
                    mapMeansDiff[off,lng] = rspMean-nrspMean

                    wholeCol = np.hstack([valsRSP, valsNRSP]) * 1
                    labels = np.hstack([np.ones(len(valsRSP)), np.zeros(len(valsNRSP))])
                    try:
                        fpr, tpr, thresholds = metrics.roc_curve(labels, wholeCol, pos_label=1)
                        auc = metrics.auc(fpr, tpr)
                        stats, p = mannwhitneyu(valsRSP, valsNRSP)

                    except:
                        print("Error in inner OFFSET/LENGTH loop. Nans RSP:",sum(np.isnan(valsRSP))," Nans NRSP:",sum(np.isnan(valsNRSP)))
                        auc = 0.5
                        p=1

                    mapAreasAUC[off,lng] = auc
                    mapAreasP[off,lng] = p


            #přidání do celkového přehledu skrz CV běhy
            mapAUCs[cr-1,:,:] = mapAreasAUC-0.5

            if cr==nsplt: #až po posledním foldu spočítám celek
                mapSumAUC = np.sum(mapAUCs, axis=0)

                #mapStdAUC = np.std(mapAUCs, axis=0)
                mapStdAUC = 1-np.std(mapAUCs, axis=0)

                mapStdAUC = np.power(mapStdAUC,4)

                #mapTotal = mapSumAUC/(1+mapStdAUC)
                mapTotal = mapStdAUC *mapSumAUC
                plt.figure(figsize=(12, 6))
                plt.subplot(1, 3, 1)
                sns.heatmap(mapSumAUC, center=0)
                plt.title("Sum (AUC-0.5)")
                plt.subplot(1, 3, 2)
                sns.heatmap(mapStdAUC)
                plt.title("1-Std(AUC)")
                plt.subplot(1, 3, 3)
                sns.heatmap(mapTotal, center=0)
                plt.title("Total")

                plt.suptitle("CV sum "+ftr+" | "+gt)
                fign="figs_maps/CVSUM_"+ftr+"_"+str(cr)+"_AUC"+gt+".png"
                plt.savefig(fign)
                plt.show()
                plt.close()

            pline()
            print("Analyzing Min and Max AUC")

            if smoothType=="uniform":
                mapAreasAUCsmooth = sflt.uniform_filter(mapAreasAUC,size=uniformSize, mode="constant") #původně nebyl mode constant
            if smoothType=="gauss":
                mapAreasAUCsmooth = sflt.gaussian_filter(mapAreasAUC,size=uniformSize)
            if smoothType == "median":
                mapAreasAUCsmooth = sflt.median_filter(mapAreasAUC, size=uniformSize, mode="constant", cval=0.5)


            #mv = np.max(mapAreasAUC)
            rmax,cmax = np.unravel_index(np.argmax(mapAreasAUCsmooth),mapAreasAUC.shape)
            rmin, cmin = np.unravel_index(np.argmin(mapAreasAUCsmooth), mapAreasAUC.shape)

            oMax = rmax*offInc+offMin
            lMax = cmax*lngInc+lngMin

            aucMax = mapAreasAUCsmooth[rmax,cmax]
            print("Max AUC at (r,c)",rmax,cmax,"Offset %.3f"%oMax,",Duration %.3f"%lMax," = %.3f"%aucMax)

            oMin = rmin*offInc+offMin
            lMin = cmin*lngInc+lngMin

            aucMin = mapAreasAUCsmooth[rmin, cmin]
            print("Min AUC at (r,c)", rmin, cmin, "Offset %.3f"%oMin, ",Duration %.3f"%lMin, " = %.3f"%aucMin)

            finAUC = aucMax
            finRow = rmax
            finCol = cmax
            finOff = oMax
            finLng = lMax

            if aucMin<1-aucMax:
                print("Loweest AUC selected")
                finAUC = aucMin
                finRow = rmin
                finCol = cmin
                finOff = oMin
                finLng = lMin

            locOffs.append(finOff)
            locDurs.append(finLng)
            locAUCs.append(finAUC)


        pline()
        print("Threshold model")
        #otestování pomocí thresholdu
        clf = DecisionTreeClassifier(random_state=0, max_depth=1)

        if "Feas_" in ftr:
            print("Analyzing ",ftr)

            #vls = data[ftr].values
            trainX = dataTrain[ftr].values
            testX = dataTest[ftr].values

            locOffs.append(np.nan)
            locDurs.append(np.nan)
            locAUCs.append(np.nan)

        else:
            trainX = vlsTrain[:,finRow,finCol]
            testX = vlsTest[:,finRow,finCol]

        outcomeTrain = outcomeTrain[~np.isnan(trainX)]
        outcomeTest = outcomeTest[~np.isnan(testX)]

        trainX = trainX[~np.isnan(trainX)]
        testX = testX[~np.isnan(testX)]


        if 1==1:
            clf.fit(trainX.reshape(-1, 1), outcomeTrain)
            predTrainY = clf.predict(trainX.reshape(-1, 1))
            predTestY = clf.predict(testX.reshape(-1, 1))

            f1Train = f1_score(outcomeTrain, predTrainY)
            f1Test = f1_score(outcomeTest, predTestY)

            locF1Tr.append(f1Train)
            locF1Te.append(f1Test)

            print(" Train F1:%.3f"%f1Train," Test F1:%.3f"%f1Test)

        #dtAreasP=pd.DataFrame(data=mapAreasP,index=offLbs,columns=lngLbs)
        #dtAreasAUC = pd.DataFrame(data=mapAreasAUC,index=offLbs,columns=lngLbs)
        #dtMeansDiff = pd.DataFrame(data=mapMeansDiff,index=offLbs,columns=lngLbs)

        #boxplots and export data
        if 1==0:
            extrem = rmax,cmax
            o = oMax
            l = lMax
            if (0.5-mapAreasAUC[rmin,cmin])>(mapAreasAUC[rmax,cmax]-0.5):
                extrem = rmin, cmin
                o = oMin
                l = lMin



            vals = vls[:,extrem[0],extrem[1]]
            dl = pd.DataFrame()
            dl[ftr] = vals
            dl["Responder"]=outcomeTrain


            data["Feas_"+ftr]=vals

            grp = []
            for r in range(data.shape[0]):
                v = "FIS/FL"
                if data["Rhythm"].values[r] in fb:
                    v="non-FIS/FL"
                grp.append(v)

            dl["Rhythm"] = grp

            plt.figure(figsize=(12,8))

            plt.subplot(1,3,1)

            try:
                ymin = dl[ftr].min()
                ymax = dl[ftr].max()
            except:
                ymin=0
                ymax=1

            sns.boxplot(data=dl,y=ftr, x="Responder")
            plt.title(ftr+" (N="+str(dl.shape[0])+") AUC %.2f"%mapAreasAUC[extrem[0],extrem[1]] +"\n at Offset %.2f"%o+", duration %.2f"%l)
            plt.legend()
            plt.ylim(ymin,ymax)
            plt.grid()

            plt.subplot(1,3,2)
            dd=dl[dl["Rhythm"]=="non-FIS/FL"]
            sns.boxplot(data=dd,y=ftr, x="Responder")
            plt.title(ftr+"Non-AF/FL (N="+str(dd.shape[0])+")")
            plt.legend()
            plt.ylabel("")

            plt.ylim(ymin, ymax)
            plt.grid()

            plt.subplot(1,3,3)
            dd=dl[dl["Rhythm"]=="FIS/FL"]
            sns.boxplot(data=dd,y=ftr, x="Responder")
            plt.title(ftr+"AF/FL (N="+str(dd.shape[0])+")")
            plt.legend()
            plt.ylim(ymin, ymax)
            plt.ylabel("")

            plt.grid()

            plt.savefig("COG_"+ftr+"_boxes_"+gt+".png")
            plt.show()


        if 1==0:
            plt.figure(figsize=(imW,imH))
            ax = sns.heatmap(dtAreasP,xticklabels=10,yticklabels=10,vmax=0.05, cmap=sns.cm.rocket_r)
            plt.title(ftr+": P-values | "+gt)
            ax.set_xlabel("Duration (s)")
            ax.set_ylabel("Offset (sec before QRS annotation mark)")

            ax.scatter(oc[0],oc[1], marker='o', s=100, color='white')
           # ax.scatter(nc[0],nc[1], marker='o', s=100, color='black')
           # ax.scatter(nc[0],nc[1], marker='*', s=100, color='white')

            ax.scatter(cmax, rmax, marker='4', s=200, color='w')
            ax.scatter(cmin, rmin, marker='4', s=200, color='w')

            ax.plot([al0[0],al1[0]],[al0[1],al1[1]],"k:")

        #    plt.grid()
            plt.savefig("COG"+ftr+"_P_"+gt+".png")
            plt.show()


        if 1==1 and not "Feas_" in ftr:
            plt.figure(figsize=(imW*2,imH))

            plt.subplot(1,2,1)

            specD = pd.DataFrame(data=mapAreasAUC,index=offLbs,columns=lngLbs)

            ax = sns.heatmap(data=specD,xticklabels=10,yticklabels=10,center=0.5)
            plt.title("CV "+str(cr)+" "+ftr+": AUC-values-train | "+gt)
            ax.set_xlabel("Duration (s)")
            ax.set_ylabel("Offset (sec before QRS annotation mark)")


            extrem = rmax,cmax
            o = oMax
            l = lMax
            if (0.5-mapAreasAUC[rmin,cmin])>(mapAreasAUC[rmax,cmax]-0.5):
                extrem = rmin, cmin
                o = oMin
                l = lMin

            c=extrem[1]
            r=extrem[0]

            #ax.scatter(c, r, marker='o', s=100, color='white')
            #ax.scatter(c, r, marker='4', s=200, color='k')

            ax.plot([al0[0],al1[0]],[al0[1],al1[1]],"w:")
            ax.plot([zl0[0], zl1[0]], [zl0[1], zl1[1]], "w:")
            plt.title("Raw map")

            #druhý plot, smooth
            plt.subplot(1, 2, 2)

            specD = pd.DataFrame(data=mapAreasAUCsmooth, index=offLbs, columns=lngLbs)

            ax = sns.heatmap(data=specD, xticklabels=10, yticklabels=10, center=0.5)
            ax.set_xlabel("Duration (s)")
            ax.set_ylabel("Offset (sec before QRS annotation mark)")

            extrem = rmax, cmax
            o = oMax
            l = lMax
            if (0.5 - mapAreasAUCsmooth[rmin, cmin]) > (mapAreasAUCsmooth[rmax, cmax] - 0.5):
                extrem = rmin, cmin
                o = oMin
                l = lMin

            c = extrem[1]
            r = extrem[0]

            ax.scatter(c, r, marker='o', s=100, color='white')
            ax.scatter(c, r, marker='4', s=200, color='k')

            ax.plot([al0[0], al1[0]], [al0[1], al1[1]], "w:")
            ax.plot([zl0[0], zl1[0]], [zl0[1], zl1[1]], "w:")
            plt.title("Smoothed uniform N=" + str(uniformSize))
            plt.suptitle("CV " + str(cr) + " " + ftr + ": AUC-values-train | " + gt)

            plt.savefig("figs_maps/CV_SMOOTH_"+ftr+"_"+str(cr)+"_AUC"+gt+".png")
            plt.show()

    #zpracování pomocí celkové sumace a std AUC


    offsets.append(locOffs)
    durations.append(locDurs)
    aucsTrain.append(locAUCs)
    f1Trains.append(locF1Tr)
    f1Tests.append(locF1Te)

print("Automated analysis done")

pline("█")
print("Building dataframe")

cvr = pd.DataFrame()
cvr["Name"]=features
cvr["Offsets"]=offsets
cvr["Durations"]=durations
cvr["AUCsTrain"]=aucsTrain
cvr["F1_Train"]=f1Trains
cvr["F1_Test"]=f1Tests

cvName = "results_data/CV5_autofeatures_"+gt+".pkl"

print("Saving to",cvName)
cvr.to_pickle(cvName)
print("Done")



